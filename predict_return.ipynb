{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SPY_3M IMPLIED VOL</th>\n",
       "      <th>SPY_HIGH</th>\n",
       "      <th>SPY_LOW</th>\n",
       "      <th>SPY_OPEN</th>\n",
       "      <th>SPY_SHORT INTEREST RATIO</th>\n",
       "      <th>SPY_ewm_log_ret_13d</th>\n",
       "      <th>SPY_ewm_log_ret_1d</th>\n",
       "      <th>SPY_ewm_log_ret_21d</th>\n",
       "      <th>SPY_ewm_log_ret_3d</th>\n",
       "      <th>...</th>\n",
       "      <th>XRT_macd_sig</th>\n",
       "      <th>XRT_rsi</th>\n",
       "      <th>XRT_rsi_13d_slope</th>\n",
       "      <th>XRT_rsi_1d_slope</th>\n",
       "      <th>XRT_rsi_21d_slope</th>\n",
       "      <th>XRT_rsi_3d_slope</th>\n",
       "      <th>XRT_rsi_5d_slope</th>\n",
       "      <th>XRT_rsi_8d_slope</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>news_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>14.0384</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>-0.006639</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>-0.010765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598815</td>\n",
       "      <td>67.988107</td>\n",
       "      <td>19.826342</td>\n",
       "      <td>-7.838144</td>\n",
       "      <td>5.204016</td>\n",
       "      <td>-1.944891</td>\n",
       "      <td>7.252436</td>\n",
       "      <td>10.295799</td>\n",
       "      <td>-0.131934</td>\n",
       "      <td>0.075776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>14.1676</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>-0.018225</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.019749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593092</td>\n",
       "      <td>59.339623</td>\n",
       "      <td>16.598506</td>\n",
       "      <td>-8.648484</td>\n",
       "      <td>-0.103102</td>\n",
       "      <td>-8.596080</td>\n",
       "      <td>-3.993711</td>\n",
       "      <td>0.899108</td>\n",
       "      <td>-0.102601</td>\n",
       "      <td>0.116118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>14.3399</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>-0.014305</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>-0.023986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567309</td>\n",
       "      <td>53.461876</td>\n",
       "      <td>14.660032</td>\n",
       "      <td>-5.877747</td>\n",
       "      <td>-4.602641</td>\n",
       "      <td>-22.364376</td>\n",
       "      <td>-16.471123</td>\n",
       "      <td>-4.402835</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>0.050569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>14.4772</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>-0.002870</td>\n",
       "      <td>-0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548476</td>\n",
       "      <td>67.244094</td>\n",
       "      <td>17.009353</td>\n",
       "      <td>13.782219</td>\n",
       "      <td>11.666405</td>\n",
       "      <td>-0.744013</td>\n",
       "      <td>-0.691608</td>\n",
       "      <td>6.508423</td>\n",
       "      <td>-0.051485</td>\n",
       "      <td>0.125229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>14.5777</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.017589</td>\n",
       "      <td>-0.002922</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544027</td>\n",
       "      <td>64.685908</td>\n",
       "      <td>12.113201</td>\n",
       "      <td>-2.558186</td>\n",
       "      <td>7.219379</td>\n",
       "      <td>5.346286</td>\n",
       "      <td>-11.140343</td>\n",
       "      <td>1.352575</td>\n",
       "      <td>0.100507</td>\n",
       "      <td>0.138343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>12.9785</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.000997</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>2.463</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.028050</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359009</td>\n",
       "      <td>67.779961</td>\n",
       "      <td>23.646861</td>\n",
       "      <td>-0.862487</td>\n",
       "      <td>24.291589</td>\n",
       "      <td>8.342875</td>\n",
       "      <td>14.908339</td>\n",
       "      <td>-0.857149</td>\n",
       "      <td>-0.048913</td>\n",
       "      <td>0.238482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>12.9736</td>\n",
       "      <td>0.005340</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>2.463</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380095</td>\n",
       "      <td>71.863118</td>\n",
       "      <td>22.659296</td>\n",
       "      <td>4.083157</td>\n",
       "      <td>26.104189</td>\n",
       "      <td>8.547421</td>\n",
       "      <td>17.008749</td>\n",
       "      <td>15.327685</td>\n",
       "      <td>0.195297</td>\n",
       "      <td>0.277311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>12.9749</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>2.463</td>\n",
       "      <td>0.023044</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.028175</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403777</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>15.808632</td>\n",
       "      <td>-5.196451</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>-1.975781</td>\n",
       "      <td>7.229581</td>\n",
       "      <td>16.047198</td>\n",
       "      <td>0.027661</td>\n",
       "      <td>0.249240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>12.9999</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.463</td>\n",
       "      <td>0.023151</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>0.027213</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421979</td>\n",
       "      <td>60.917031</td>\n",
       "      <td>2.283937</td>\n",
       "      <td>-5.749636</td>\n",
       "      <td>7.498227</td>\n",
       "      <td>-6.862930</td>\n",
       "      <td>-2.398666</td>\n",
       "      <td>8.045409</td>\n",
       "      <td>-0.075382</td>\n",
       "      <td>0.255385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>13.0401</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>-0.002901</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>2.287</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436106</td>\n",
       "      <td>61.853448</td>\n",
       "      <td>0.459851</td>\n",
       "      <td>0.936418</td>\n",
       "      <td>9.661381</td>\n",
       "      <td>-10.009670</td>\n",
       "      <td>-6.788999</td>\n",
       "      <td>6.999079</td>\n",
       "      <td>0.036756</td>\n",
       "      <td>0.164516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  SPY_3M IMPLIED VOL  SPY_HIGH   SPY_LOW  SPY_OPEN  \\\n",
       "0     2015-01-02             14.0384  0.006498 -0.006639  0.004078   \n",
       "1     2015-01-05             14.1676 -0.005173 -0.020061 -0.006152   \n",
       "2     2015-01-06             14.3399  0.004945 -0.014305  0.001833   \n",
       "3     2015-01-07             14.4772  0.014409  0.005291  0.007975   \n",
       "4     2015-01-08             14.5777  0.018851  0.008270  0.008368   \n",
       "...          ...                 ...       ...       ...       ...   \n",
       "1245  2019-12-24             12.9785  0.000934 -0.000997  0.000778   \n",
       "1246  2019-12-26             12.9736  0.005340  0.001276  0.001307   \n",
       "1247  2019-12-27             12.9749  0.002659 -0.002046  0.002474   \n",
       "1248  2019-12-30             12.9999  0.000743 -0.007181  0.000279   \n",
       "1249  2019-12-31             13.0401  0.003265 -0.002901 -0.001714   \n",
       "\n",
       "      SPY_SHORT INTEREST RATIO  SPY_ewm_log_ret_13d  SPY_ewm_log_ret_1d  \\\n",
       "0                        1.507             0.005375           -0.000535   \n",
       "1                        1.507             0.006181           -0.018225   \n",
       "2                        1.507             0.006670           -0.009464   \n",
       "3                        1.507             0.006085            0.012384   \n",
       "4                        1.507             0.004606            0.017589   \n",
       "...                        ...                  ...                 ...   \n",
       "1245                     2.463             0.021663            0.000031   \n",
       "1246                     2.463             0.022183            0.005309   \n",
       "1247                     2.463             0.023044           -0.000248   \n",
       "1248                     2.463             0.023151           -0.005528   \n",
       "1249                     2.287             0.023185            0.002426   \n",
       "\n",
       "      SPY_ewm_log_ret_21d  SPY_ewm_log_ret_3d  ...  XRT_macd_sig    XRT_rsi  \\\n",
       "0                0.006782           -0.010765  ...      0.598815  67.988107   \n",
       "1                0.003427           -0.019749  ...      0.593092  59.339623   \n",
       "2               -0.000383           -0.023986  ...      0.567309  53.461876   \n",
       "3               -0.002870           -0.019645  ...      0.548476  67.244094   \n",
       "4               -0.002922            0.000432  ...      0.544027  64.685908   \n",
       "...                   ...                 ...  ...           ...        ...   \n",
       "1245             0.028050            0.003051  ...      0.359009  67.779961   \n",
       "1246             0.028235            0.004959  ...      0.380095  71.863118   \n",
       "1247             0.028175            0.005026  ...      0.403777  66.666667   \n",
       "1248             0.027213            0.002279  ...      0.421979  60.917031   \n",
       "1249             0.026897           -0.000535  ...      0.436106  61.853448   \n",
       "\n",
       "      XRT_rsi_13d_slope  XRT_rsi_1d_slope  XRT_rsi_21d_slope  \\\n",
       "0             19.826342         -7.838144           5.204016   \n",
       "1             16.598506         -8.648484          -0.103102   \n",
       "2             14.660032         -5.877747          -4.602641   \n",
       "3             17.009353         13.782219          11.666405   \n",
       "4             12.113201         -2.558186           7.219379   \n",
       "...                 ...               ...                ...   \n",
       "1245          23.646861         -0.862487          24.291589   \n",
       "1246          22.659296          4.083157          26.104189   \n",
       "1247          15.808632         -5.196451          15.789474   \n",
       "1248           2.283937         -5.749636           7.498227   \n",
       "1249           0.459851          0.936418           9.661381   \n",
       "\n",
       "      XRT_rsi_3d_slope  XRT_rsi_5d_slope  XRT_rsi_8d_slope  tweet_sentiment  \\\n",
       "0            -1.944891          7.252436         10.295799        -0.131934   \n",
       "1            -8.596080         -3.993711          0.899108        -0.102601   \n",
       "2           -22.364376        -16.471123         -4.402835         0.025503   \n",
       "3            -0.744013         -0.691608          6.508423        -0.051485   \n",
       "4             5.346286        -11.140343          1.352575         0.100507   \n",
       "...                ...               ...               ...              ...   \n",
       "1245          8.342875         14.908339         -0.857149        -0.048913   \n",
       "1246          8.547421         17.008749         15.327685         0.195297   \n",
       "1247         -1.975781          7.229581         16.047198         0.027661   \n",
       "1248         -6.862930         -2.398666          8.045409        -0.075382   \n",
       "1249        -10.009670         -6.788999          6.999079         0.036756   \n",
       "\n",
       "      news_sentiment  \n",
       "0           0.075776  \n",
       "1           0.116118  \n",
       "2           0.050569  \n",
       "3           0.125229  \n",
       "4           0.138343  \n",
       "...              ...  \n",
       "1245        0.238482  \n",
       "1246        0.277311  \n",
       "1247        0.249240  \n",
       "1248        0.255385  \n",
       "1249        0.164516  \n",
       "\n",
       "[1250 rows x 421 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv(\"./data/stocks_ti.csv\")\n",
    "\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_regression_data(df, days=13, random_state=257):\n",
    "    \"\"\"Prepare data for regressor\"\"\"\n",
    "    # Create target variable\n",
    "    df[\"y_true\"] = df[\"SPY_ewm_log_ret_1d\"].rolling(window=days).sum().shift(-days)\n",
    "    df = df.dropna()\n",
    "    # Define features\n",
    "    y_true = df[\"y_true\"].values\n",
    "    if \"DATE\" in df.columns:\n",
    "        X = df.drop(columns=[\"DATE\", \"y_true\"]).values\n",
    "    else:\n",
    "        X = df.drop(columns=[\"y_true\"]).values\n",
    "    assert len(X) == len(y_true), \"X and y_true must have the same length\"\n",
    "\n",
    "    # train test split\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     X, y_true, test_size=0.2, random_state=random_state, shuffle=True\n",
    "    # )\n",
    "\n",
    "    test_size = 0.2\n",
    "    # Calculate split index\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "\n",
    "    # Split into training and testing sets based on the calculated index\n",
    "    X_train = X[:split_idx]\n",
    "    X_test = X[split_idx:]\n",
    "    y_train = y_true[:split_idx]\n",
    "    y_test = y_true[split_idx:]\n",
    "\n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import prep_regression_data, feature_type_map\n",
    "from utils import feature_type_map\n",
    "\n",
    "\n",
    "fm = feature_type_map(stocks)\n",
    "columns1 = list(set(fm[\"spy_returns\"]))\n",
    "columns2 = list(set(fm[\"returns\"]))\n",
    "columns3 = list(set(fm[\"returns\"] + fm[\"sentiment\"]))\n",
    "columns4 = list(set(fm[\"returns\"] + fm[\"technical\"]))\n",
    "columns5 = stocks.columns\n",
    "\n",
    "# dictionary to store tuple of (pred, confusion_matrix, classifier) for each day, for each feature type, for each model\n",
    "models_key = {\n",
    "    \"linear_regression\": {\n",
    "        \"spy_returns\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns_sentiment\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns_technical\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"all_features\": {1: None, 5: None, 13: None, 21: None},\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"spy_returns\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns_sentiment\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns_technical\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"all_features\": {1: None, 5: None, 13: None, 21: None},\n",
    "    },\n",
    "    \"xgboost\": {\n",
    "        \"spy_returns\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns_sentiment\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"sector_returns_technical\": {1: None, 5: None, 13: None, 21: None},\n",
    "        \"all_features\": {1: None, 5: None, 13: None, 21: None},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regressor(X_train, X_test, y_train, y_test):\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE:{test_mse}, R2:{test_r2}\")\n",
    "\n",
    "    return clf, y_pred\n",
    "\n",
    "\n",
    "def random_forest_regressor(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Random Forest Regressor with Random Search CV\"\"\"\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    # Define the model\n",
    "    clf = RandomForestRegressor(random_state=257)\n",
    "\n",
    "    # Set up the parameter grid to sample from during fitting\n",
    "    param_distributions = {\n",
    "        \"n_estimators\": np.arange(100, 1100, 100),\n",
    "        \"max_depth\": [None] + list(np.arange(10, 110, 10)),\n",
    "        \"min_samples_split\": np.arange(2, 21),\n",
    "        \"min_samples_leaf\": np.arange(1, 21),\n",
    "    }\n",
    "\n",
    "    # Create the random search with CV object\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=100,  # Number of parameter settings sampled\n",
    "        scoring=\"neg_mean_squared_error\",  # Minimize MSE\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        verbose=1,  # Higher the number, more the verbosity\n",
    "        random_state=257,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model found by random search\n",
    "    best_clf = random_search.best_estimator_\n",
    "\n",
    "    # Predict on test data using the best model\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"MSE:{test_mse}, R2:{test_r2}\")\n",
    "\n",
    "    return best_clf, y_pred\n",
    "\n",
    "\n",
    "def xgboost_regressor(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"XGBoost Regressor with Random Search CV\"\"\"\n",
    "    from xgboost import XGBRegressor\n",
    "\n",
    "    # Define the model\n",
    "    clf = XGBRegressor(random_state=257)\n",
    "\n",
    "    # Set up the parameter grid to sample from during fitting\n",
    "    param_distributions = {\n",
    "        \"n_estimators\": np.arange(100, 1100, 100),\n",
    "        \"max_depth\": np.arange(3, 15),\n",
    "        \"learning_rate\": np.linspace(0.01, 0.3, num=30),\n",
    "        \"subsample\": np.linspace(0.5, 1.0, num=6),\n",
    "        \"colsample_bytree\": np.linspace(0.5, 1.0, num=6),\n",
    "    }\n",
    "\n",
    "    # Create the random search with CV object\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=100,  # Number of parameter settings sampled\n",
    "        scoring=\"neg_mean_squared_error\",  # Minimize MSE\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        verbose=1,  # Higher the number, more the verbosity\n",
    "        random_state=257,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model found by random search\n",
    "    best_clf = random_search.best_estimator_\n",
    "\n",
    "    # Predict on test data using the best model\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"MSE:{test_mse}, R2:{test_r2}\")\n",
    "\n",
    "    return best_clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression on 21 day(s) with spy_returns...\n",
      "MSE:0.0012419145650559996, R2:-0.2007732881263622\n",
      "Random Forest on 21 day(s) with spy_returns...\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "MSE:0.0012868329205509123, R2:-0.24420361976308258\n",
      "XGBoost on 21 day(s) with spy_returns...\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "MSE:0.0012306832237762432, R2:-0.18991401086363524\n",
      "Linear Regression on 21 day(s) with sector_returns...\n",
      "MSE:0.0019929863593322827, R2:-0.9269641014142578\n",
      "Random Forest on 21 day(s) with sector_returns...\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "MSE:0.0021081060388732815, R2:-1.038270176743413\n",
      "XGBoost on 21 day(s) with sector_returns...\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "MSE:0.002377022561862841, R2:-1.298278221279972\n",
      "Linear Regression on 21 day(s) with sector_returns_sentiment...\n",
      "MSE:0.002100387248599921, R2:-1.0308070891545476\n",
      "Random Forest on 21 day(s) with sector_returns_sentiment...\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# random forest\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m day(s) with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m models_key[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m][features_type][day_no] \u001b[38;5;241m=\u001b[39m random_forest_regressor(\n\u001b[1;32m     33\u001b[0m     X_train, X_test, y_train, y_test\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# xgboost\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m day(s) with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 43\u001b[0m, in \u001b[0;36mrandom_forest_regressor\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     31\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     32\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mclf,\n\u001b[1;32m     33\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Use all available cores\u001b[39;00m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Best model found by random search\u001b[39;00m\n\u001b[1;32m     46\u001b[0m best_clf \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i, day_no in enumerate([1, 5, 13, 21]):\n",
    "for i, day_no in enumerate([21]):\n",
    "    for j, features in enumerate([columns1, columns2, columns3, columns4, columns5]):\n",
    "        features_type = [\n",
    "            \"spy_returns\",\n",
    "            \"sector_returns\",\n",
    "            \"sector_returns_sentiment\",\n",
    "            \"sector_returns_technical\",\n",
    "            \"all_features\",\n",
    "        ][j]\n",
    "\n",
    "        # prep data\n",
    "        X_train, X_test, y_train, y_test = prep_regression_data(\n",
    "            stocks[features].copy(), day_no\n",
    "        )\n",
    "\n",
    "        ## models\n",
    "        # from utils import (\n",
    "        #     Linear_regression,\n",
    "        #     random_forest_classifier,\n",
    "        #     xgboost_classifier,\n",
    "        # )\n",
    "\n",
    "        # logistic regression\n",
    "        print(f\"Linear Regression on {day_no} day(s) with {features_type}...\")\n",
    "        models_key[\"linear_regression\"][features_type][day_no] = linear_regressor(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "\n",
    "        # random forest\n",
    "        print(f\"Random Forest on {day_no} day(s) with {features_type}...\")\n",
    "        models_key[\"random_forest\"][features_type][day_no] = random_forest_regressor(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "\n",
    "        # xgboost\n",
    "        print(f\"XGBoost on {day_no} day(s) with {features_type}...\")\n",
    "        models_key[\"xgboost\"][features_type][day_no] = xgboost_regressor(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
